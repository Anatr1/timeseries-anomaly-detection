{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25_DoksTnz6A"
      },
      "source": [
        "# Lab 7: Time-series Anomaly Detection\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r__CaWOokrp6"
      },
      "source": [
        "Pandas was updated on 03/04/2023 to version 2.0, which is not compatibile with tsfel. Dowgrade to 1.5.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNzvafzV0UQk",
        "outputId": "cbfd9a2b-b23a-4958-a4ad-580bb87df20b"
      },
      "outputs": [],
      "source": [
        "# !pip install pandas==1.5.3\n",
        "# !pip install tsfel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3dOdx_Swt7s"
      },
      "source": [
        "## Import and settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLCrldUjk0g0",
        "outputId": "f185bf78-feb1-4f7f-f718-81e0c655703e"
      },
      "outputs": [],
      "source": [
        "# !pip install keras_tuner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Ab1falMquEfu"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import tsfel\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import preprocessing\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "\n",
        "from plots import *\n",
        "from dataset import *\n",
        "from metrics import *\n",
        "from models_funtions import *\n",
        "\n",
        "# Set style for matplotlib\n",
        "plt.style.use(\"Solarize_Light2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Path to the root directory of the dataset\n",
        "ROOTDIR_DATASET_NORMAL =  '../dataset/normal' #'/content/drive/MyDrive/dataset/normal'\n",
        "ROOTDIR_DATASET_ANOMALY = '../dataset/collisions'#'/content/drive/MyDrive/dataset/collisions'\n",
        "\n",
        "# TF_ENABLE_ONEDNN_OPTS=0 means that the model will not use the oneDNN library for optimization\n",
        "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Various parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arGQVa5UtUh0",
        "outputId": "63e0eca7-17f0-45c6-b1a3-5a0c97cc243c"
      },
      "outputs": [],
      "source": [
        "#freq = '1.0'\n",
        "freq = '0.1'\n",
        "#freq = '0.01'\n",
        "#freq = '0.005'\n",
        "\n",
        "file_name_normal = \"_20220811_rbtc_\"\n",
        "file_name_collisions = \"_collision_20220811_rbtc_\"\n",
        "\n",
        "recording_normal = [0, 2, 3, 4]\n",
        "recording_collisions = [1, 5]\n",
        "\n",
        "features_folder_normal = \"../features/normal/\"\n",
        "features_folder_collisions = \"../features/collisions/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "id": "hiOnD99H1K4t",
        "outputId": "bfa44000-56d4-4cc0-c004-96f40c0cf677"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading data.\n",
            "Found 31 different actions.\n",
            "Loading data done.\n",
            "\n",
            "Computing features.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "              <p>\n",
              "                  Progress: 0% Complete\n",
              "              <p/>\n",
              "              <progress\n",
              "                  value='0'\n",
              "                  max='32',\n",
              "                  style='width: 25%',\n",
              "              >\n",
              "                  0\n",
              "              </progress>\n",
              "\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df_features_normal, df_normal_raw, _, action2int_normal_raw = get_dataframes(ROOTDIR_DATASET_NORMAL, file_name_normal, recording_normal, freq, features_folder=f\"{features_folder_normal}\")\n",
        "df_features_collisions, df_collisions_raw, df_collisions_raw_action, action2int_collisions_raw = get_dataframes(ROOTDIR_DATASET_ANOMALY, file_name_collisions, recording_collisions, freq, features_folder=f\"{features_folder_collisions}1_5/\")\n",
        "df_features_collisions_1, df_collisions_raw_1, df_collisions_raw_action_1, action2int_collisions_raw_action_1 = get_dataframes(ROOTDIR_DATASET_ANOMALY, file_name_collisions, [1], freq, features_folder=f\"{features_folder_collisions}1/\")\n",
        "df_features_collisions_5, df_collisions_raw_5, df_collisions_raw_action_5, action2int_collisions_raw_action_5 = get_dataframes(ROOTDIR_DATASET_ANOMALY, file_name_collisions, [5], freq, features_folder=f\"{features_folder_collisions}5/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, y_train, X_test, y_test, df_test = get_train_test_data(df_features_normal, df_features_collisions, full_normal=True)\n",
        "X_train_1, y_train_1, X_test_1, y_test_1, df_test_1 = get_train_test_data(df_features_normal, df_features_collisions_1, full_normal=True)\n",
        "X_train_5, y_train_5, X_test_5, y_test_5, df_test_5 = get_train_test_data(df_features_normal, df_features_collisions_5, full_normal=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_test_1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_test_5.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Collisions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "collisions_rec1, collisions_init1 = get_collisions('1', ROOTDIR_DATASET_ANOMALY)\n",
        "collisions_rec5, collisions_init5 = get_collisions('5', ROOTDIR_DATASET_ANOMALY)\n",
        "\n",
        "# Merge the collisions of the two recordings in one dataframe\n",
        "collisions_rec = pd.concat([collisions_rec1, collisions_rec5])\n",
        "collisions_init = pd.concat([collisions_init1, collisions_init5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "collisions_zones, y_collisions = get_collisions_zones_and_labels(collisions_rec, collisions_init, df_features_collisions)\n",
        "collisions_zones_1, y_collisions_1 = get_collisions_zones_and_labels(collisions_rec1, collisions_init1, df_features_collisions_1)\n",
        "collisions_zones_5, y_collisions_5 = get_collisions_zones_and_labels(collisions_rec5, collisions_init5, df_features_collisions_5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Random forest classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_estims = [10, 100, 1000]\n",
        "crits = ['gini', 'entropy', 'log_loss']\n",
        "max_dept = [None, 50, 100, 1000]\n",
        "min_s_splits = [2, 3]\n",
        "max_features = ['sqrt', 'log2', None]\n",
        "\n",
        "classifier = RandomForestClassifier(\n",
        "    n_estimators = 100,\n",
        "    criterion = 'gini',\n",
        "    max_depth = 1000,\n",
        "    min_samples_split = 2,\n",
        "    max_features = 'sqrt'\n",
        "    )\n",
        "# Train the RandomForestClassifier on normal data\n",
        "classifier.fit(X_train, y_train)\n",
        "print(\"Random Forest training completed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_test_predict = classifier.predict_proba(X_test.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_test_predict.argmax(axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwfnwDPlw1hh"
      },
      "source": [
        "Check the model performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 806
        },
        "id": "sl_jrW8Xq0dW",
        "outputId": "2b927f88-dab5-4b35-cec2-e676bf8cdaa4"
      },
      "outputs": [],
      "source": [
        "# Get confusion matrix\n",
        "cm = confusion_matrix(y_test, y_test_predict.argmax(axis=1), labels=list(action2int_normal_raw.values()))\n",
        "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
        "int2action = {v: k for k, v in action2int_normal_raw.items()}\n",
        "seaborn_cm(cm,\n",
        "            ax,\n",
        "            [int2action[l] for l in action2int_normal_raw.values()], fontsize=8, xrotation=90)\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkZT_TOlRvaC"
      },
      "source": [
        "# **TODO** Compute uncertainty"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6i80mhnsnWV2",
        "outputId": "ad7eaf6c-db21-4402-d400-3fc142c036d0"
      },
      "outputs": [],
      "source": [
        "n_mc = 10\n",
        "preds_array = np.array([classifier.predict_proba(X_test.values) for _ in range(n_mc)])\n",
        "preds_bayes_mean = np.mean(np.array(preds_array), axis = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Qe_bl0Ypauk",
        "outputId": "b0108ce1-5b99-472c-825e-7749329f95df"
      },
      "outputs": [],
      "source": [
        "uncertainties_bayes = dict()\n",
        "uncertainties_bayes[\"correct\"] = Confidence(preds_array.mean(axis=0)[(preds_bayes_mean.argmax(axis=1) == y_test), :]).compute_uncertainty_metrics()\n",
        "uncertainties_bayes[\"wrong\"] = Confidence(preds_array.mean(axis=0)[(preds_bayes_mean.argmax(axis=1) != y_test), :]).compute_uncertainty_metrics()\n",
        "uncertainties_bayes[\"all\"] = Confidence(preds_array.mean(axis=0)).compute_uncertainty_metrics()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "uncertainties_bayes[\"correct\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 718
        },
        "id": "B-R64RsBpt5s",
        "outputId": "89d9009f-ecbb-4ae9-84d7-01a3252576ce"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(len(uncertainties_bayes['correct'].keys()), 3, figsize=(15, 9))\n",
        "for ax, measure in zip(axes, uncertainties_bayes['correct'].keys()):\n",
        "    ax[0].set_title(f\"Wrong - {measure}\")\n",
        "    ax[0].hist(uncertainties_bayes['wrong'][measure], color=\"red\", log=False, bins=25, edgecolor='black', linewidth=1.2, alpha=0.5);\n",
        "    ax[1].set_title(f\"Correct - {measure}\")\n",
        "    ax[1].hist(uncertainties_bayes['correct'][measure], color=\"green\", log=False, bins=25, edgecolor='black', linewidth=1.2, alpha=0.5);\n",
        "    ax[2].set_title(f\"All - {measure}\")\n",
        "    ax[2].hist(uncertainties_bayes['all'][measure], color=\"blue\", log=False, bins=25, edgecolor='black', linewidth=1.2, alpha=0.5);\n",
        "fig.suptitle(\"Bayes MLP\", fontsize=20)\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-L0JBb09p9ws"
      },
      "source": [
        "# Load collisions and extract features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pv9y50Wzq1Iz"
      },
      "outputs": [],
      "source": [
        "collisions = pd.read_excel(os.path.join(ROOTDIR_DATASET_ANOMALY, \"20220811_collisions_timestamp.xlsx\"))\n",
        "collisions_init = collisions[collisions['Inizio/fine'] == \"i\"].Timestamp - pd.to_timedelta([2] * len(collisions[collisions['Inizio/fine'] == \"i\"].Timestamp), 'h')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCecnHINrqDK",
        "outputId": "a4f03492-95e7-448b-9fdb-5572da58b22b"
      },
      "outputs": [],
      "source": [
        "filepath_csv = [os.path.join(ROOTDIR_DATASET_ANOMALY, f\"rec{r}_collision_20220811_rbtc_0.1s.csv\") for r in [1, 5]]\n",
        "filepath_meta = [os.path.join(ROOTDIR_DATASET_ANOMALY, f\"rec{r}_collision_20220811_rbtc_0.1s.metadata\") for r in [1, 5]]\n",
        "df_action, df, df_meta, action2int = get_df_action(filepath_csv, filepath_meta)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "filepath_csv_1 = [os.path.join(ROOTDIR_DATASET_ANOMALY, f\"rec{r}_collision_20220811_rbtc_0.1s.csv\") for r in [1]]\n",
        "filepath_meta_1 = [os.path.join(ROOTDIR_DATASET_ANOMALY, f\"rec{r}_collision_20220811_rbtc_0.1s.metadata\") for r in [1]]\n",
        "df_action_1, df_1, df_meta_1, action2int_1 = get_df_action(filepath_csv_1, filepath_meta_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "filepath_csv_5 = [os.path.join(ROOTDIR_DATASET_ANOMALY, f\"rec{r}_collision_20220811_rbtc_0.1s.csv\") for r in [5]]\n",
        "filepath_meta_5 = [os.path.join(ROOTDIR_DATASET_ANOMALY, f\"rec{r}_collision_20220811_rbtc_0.1s.metadata\") for r in [5]]\n",
        "df_action_5, df_5, df_meta_5, action2int_5 = get_df_action(filepath_csv_5, filepath_meta_5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "6etgQk3OsG1d",
        "outputId": "7cd38fd3-dcfa-4c36-9f0c-965fb36d1785"
      },
      "outputs": [],
      "source": [
        "start_time = time.time()\n",
        "df_features_collision = get_features_ts(\"statistical\", df_action, df_meta, 10, action2int, None)\n",
        "df_features_collision_1 = get_features_ts(\"statistical\", df_action_1, df_meta_1, 10, action2int_1, None)\n",
        "df_features_collision_5 = get_features_ts(\"statistical\", df_action_5, df_meta_5, 10, action2int_5, None)\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_features_collision_1.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Epjubc7aa9mH"
      },
      "source": [
        "Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrH9YmS8a_C9",
        "outputId": "60d1b4ed-66b8-4ff2-eb79-c8ce80303765"
      },
      "outputs": [],
      "source": [
        "# df_features_collision.isnull().values.any()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jb_DEeO2bGbz"
      },
      "outputs": [],
      "source": [
        "df_features_collision_nonan = df_features_collision.fillna(0)\n",
        "df_features_collision_nonan_1 = df_features_collision_1.fillna(0)\n",
        "df_features_collision_nonan_5 = df_features_collision_5.fillna(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_features_collision_nonan_1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v3iC8BAebO8s"
      },
      "outputs": [],
      "source": [
        "# X_collision = df_features_collision_nonan.drop([\"label\", \"start\", \"end\"], axis=1)\n",
        "# y_collision = df_features_collision_nonan[\"label\"]\n",
        "# X_collision.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# X_collision_1 = df_features_collision_nonan_1.drop([\"label\", \"start\", \"end\"], axis=1)\n",
        "# y_collision_1 = df_features_collision_nonan_1[\"label\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# X_collision_5 = df_features_collision_nonan_5.drop([\"label\", \"start\", \"end\"], axis=1)\n",
        "# y_collision_5 = df_features_collision_nonan_5[\"label\"]\n",
        "# X_collision_5.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0XBuZBmxNtz"
      },
      "source": [
        "# **TODO** Compute uncertainty"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJpRVJikbkjH",
        "outputId": "5dd140b3-60ba-4f23-817d-d82dc1ebab39"
      },
      "outputs": [],
      "source": [
        "preds_array_collisions = np.array([classifier.predict_proba(X_test.values) for _ in range(n_mc)])\n",
        "preds_bayes_mean_collision = np.mean(np.array(preds_array_collisions), axis = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "preds_array_collisions_1 = np.array([classifier.predict_proba(X_test_1.values) for _ in range(n_mc)])\n",
        "preds_bayes_mean_collision_1 = np.mean(np.array(preds_array_collisions_1), axis = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "preds_array_collisions_5 = np.array([classifier.predict_proba(X_test_5.values) for _ in range(n_mc)])\n",
        "preds_bayes_mean_collision_5 = np.mean(np.array(preds_array_collisions_5), axis = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uunCaSdcb4Eu",
        "outputId": "5a95c2e6-c219-4760-9abd-91ff74a898c8"
      },
      "outputs": [],
      "source": [
        "uncertainties_bayes = dict()\n",
        "uncertainties_bayes[\"correct\"] = Confidence(preds_array_collisions.mean(axis=0)[(preds_bayes_mean_collision.argmax(axis=1) == y_collisions), :]).compute_uncertainty_metrics()\n",
        "uncertainties_bayes[\"wrong\"] = Confidence(preds_array_collisions.mean(axis=0)[(preds_bayes_mean_collision.argmax(axis=1) != y_collisions), :]).compute_uncertainty_metrics()\n",
        "uncertainties_bayes[\"all\"] = Confidence(preds_array_collisions.mean(axis=0)).compute_uncertainty_metrics()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "uncertainties_bayes_1 = dict()\n",
        "uncertainties_bayes_1[\"correct\"] = Confidence(preds_array_collisions_1.mean(axis=0)[(preds_bayes_mean_collision_1.argmax(axis=1) == y_collisions_1), :]).compute_uncertainty_metrics()\n",
        "uncertainties_bayes_1[\"wrong\"] = Confidence(preds_array_collisions_1.mean(axis=0)[(preds_bayes_mean_collision_1.argmax(axis=1) != y_collisions_1), :]).compute_uncertainty_metrics()\n",
        "uncertainties_bayes_1[\"all\"] = Confidence(preds_array_collisions_1.mean(axis=0)).compute_uncertainty_metrics()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "uncertainties_bayes_5 = dict()\n",
        "uncertainties_bayes_5[\"correct\"] = Confidence(preds_array_collisions_5.mean(axis=0)[(preds_bayes_mean_collision_5.argmax(axis=1) == y_collisions_5), :]).compute_uncertainty_metrics()\n",
        "uncertainties_bayes_5[\"wrong\"] = Confidence(preds_array_collisions_5.mean(axis=0)[(preds_bayes_mean_collision_5.argmax(axis=1) != y_collisions_5), :]).compute_uncertainty_metrics()\n",
        "uncertainties_bayes_5[\"all\"] = Confidence(preds_array_collisions_5.mean(axis=0)).compute_uncertainty_metrics()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 718
        },
        "id": "X4cBEIfYcN7e",
        "outputId": "dd87ae72-c1aa-4aa9-d984-390d32dfcbd3"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(len(uncertainties_bayes['correct'].keys()), 3, figsize=(15, 9))\n",
        "for ax, measure in zip(axes, uncertainties_bayes['correct'].keys()):\n",
        "    ax[0] .set_title(f\"Wrong - {measure}\")\n",
        "    ax[0].hist(uncertainties_bayes['wrong'][measure], color=\"red\", log=False, bins=25, edgecolor='black', linewidth=1.2, alpha=0.5);\n",
        "    ax[1] .set_title(f\"Correct - {measure}\")\n",
        "    ax[1].hist(uncertainties_bayes['correct'][measure], color=\"green\", log=False, bins=25, edgecolor='black', linewidth=1.2, alpha=0.5);\n",
        "    ax[2] .set_title(f\"All - {measure}\")\n",
        "    ax[2].hist(uncertainties_bayes['all'][measure], color=\"blue\", log=False, bins=25, edgecolor='black', linewidth=1.2, alpha=0.5);\n",
        "fig.suptitle(\"Random forest\", fontsize=20)\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(len(uncertainties_bayes_1['correct'].keys()), 3, figsize=(15, 9))\n",
        "for ax, measure in zip(axes, uncertainties_bayes_1['correct'].keys()):\n",
        "    ax[0] .set_title(f\"Wrong - {measure}\")\n",
        "    ax[0].hist(uncertainties_bayes_1['wrong'][measure], color=\"red\", log=False, bins=25, edgecolor='black', linewidth=1.2, alpha=0.5);\n",
        "    ax[1] .set_title(f\"Correct - {measure}\")\n",
        "    ax[1].hist(uncertainties_bayes_1['correct'][measure], color=\"green\", log=False, bins=25, edgecolor='black', linewidth=1.2, alpha=0.5);\n",
        "    ax[2] .set_title(f\"All - {measure}\")\n",
        "    ax[2].hist(uncertainties_bayes_1['all'][measure], color=\"blue\", log=False, bins=25, edgecolor='black', linewidth=1.2, alpha=0.5);\n",
        "fig.suptitle(\"Random forest\", fontsize=20)\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(len(uncertainties_bayes_5['correct'].keys()), 3, figsize=(15, 9))\n",
        "for ax, measure in zip(axes, uncertainties_bayes_5['correct'].keys()):\n",
        "    ax[0] .set_title(f\"Wrong - {measure}\")\n",
        "    ax[0].hist(uncertainties_bayes_5['wrong'][measure], color=\"red\", log=False, bins=25, edgecolor='black', linewidth=1.2, alpha=0.5);\n",
        "    ax[1] .set_title(f\"Correct - {measure}\")\n",
        "    ax[1].hist(uncertainties_bayes_5['correct'][measure], color=\"green\", log=False, bins=25, edgecolor='black', linewidth=1.2, alpha=0.5);\n",
        "    ax[2] .set_title(f\"All - {measure}\")\n",
        "    ax[2].hist(uncertainties_bayes_5['all'][measure], color=\"blue\", log=False, bins=25, edgecolor='black', linewidth=1.2, alpha=0.5);\n",
        "fig.suptitle(\"Random forest\", fontsize=20)\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zphGuG07xQuA"
      },
      "source": [
        "# Assess TAD algorithm performance via ROC curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XeCRc71JLwth"
      },
      "outputs": [],
      "source": [
        "roc_dict = dict()\n",
        "for confidence_metric in uncertainties_bayes['correct'].keys():\n",
        "    confidence = uncertainties_bayes['all'][confidence_metric]\n",
        "    if confidence_metric == \"entropy\":\n",
        "        confidence = 1- confidence\n",
        "    sens = list()\n",
        "    fpr = list()\n",
        "    for threshold in np.arange(0, 1, 0.1):\n",
        "        df_not_confident = df_features_collision_nonan[confidence <= threshold]\n",
        "        anomaly_indexes = list()\n",
        "        tp = 0\n",
        "        for anomaly in collisions_init:\n",
        "            for index, row in df_not_confident.iterrows():\n",
        "                if anomaly >= row['start'] and anomaly <= row['end']:\n",
        "                    anomaly_indexes.append(index)\n",
        "                    tp += 1\n",
        "\n",
        "        cm_anomaly = np.zeros((2, 2))\n",
        "        n_samples = len(df_features_collision_nonan)\n",
        "        n_not_collisions = n_samples - len(collisions_init)\n",
        "        n_detected = len(df_not_confident)\n",
        "\n",
        "        fp = n_detected - tp\n",
        "        fn = len(collisions_init) - tp\n",
        "        tn = n_not_collisions - fp\n",
        "        cm_anomaly[0][0] = tn\n",
        "        cm_anomaly[1][1] = tp\n",
        "        cm_anomaly[0][1] = fp\n",
        "        cm_anomaly[1][0] = fn\n",
        "        sens.append(tp / (tp + fn))\n",
        "        fpr.append(1 - tn / (fp + tn))\n",
        "    roc_dict[confidence_metric] = (fpr, sens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "id": "KwIZ9uJcR8bT",
        "outputId": "81f59ca0-a498-4b9f-ce28-88debac85350"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1, 1)\n",
        "for confidence_metric in uncertainties_bayes['correct'].keys():\n",
        "    ax.plot(roc_dict[confidence_metric][0], roc_dict[confidence_metric][1], label=confidence_metric)\n",
        "ax.legend();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "roc_dict = dict()\n",
        "for confidence_metric in uncertainties_bayes_1['correct'].keys():\n",
        "    confidence = uncertainties_bayes_1['all'][confidence_metric]\n",
        "    if confidence_metric == \"entropy\":\n",
        "        confidence = 1- confidence\n",
        "    sens = list()\n",
        "    fpr = list()\n",
        "    for threshold in np.arange(0, 1, 0.1):\n",
        "        df_not_confident = df_features_collision_nonan_1[confidence <= threshold]\n",
        "        anomaly_indexes = list()\n",
        "        tp = 0\n",
        "        for anomaly in collisions_init:\n",
        "            for index, row in df_not_confident.iterrows():\n",
        "                if anomaly >= row['start'] and anomaly <= row['end']:\n",
        "                    anomaly_indexes.append(index)\n",
        "                    tp += 1\n",
        "\n",
        "        cm_anomaly = np.zeros((2, 2))\n",
        "        n_samples = len(df_features_collision_nonan_1)\n",
        "        n_not_collisions = n_samples - len(collisions_init)\n",
        "        n_detected = len(df_not_confident)\n",
        "\n",
        "        fp = n_detected - tp\n",
        "        fn = len(collisions_init) - tp\n",
        "        tn = n_not_collisions - fp\n",
        "        cm_anomaly[0][0] = tn\n",
        "        cm_anomaly[1][1] = tp\n",
        "        cm_anomaly[0][1] = fp\n",
        "        cm_anomaly[1][0] = fn\n",
        "        sens.append(tp / (tp + fn))\n",
        "        fpr.append(1 - tn / (fp + tn))\n",
        "    roc_dict[confidence_metric] = (fpr, sens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "confidence.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_features_collision_nonan_1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1, 1)\n",
        "for confidence_metric in uncertainties_bayes_1['correct'].keys():\n",
        "    ax.plot(roc_dict[confidence_metric][0], roc_dict[confidence_metric][1], label=confidence_metric)\n",
        "ax.legend();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "roc_dict = dict()\n",
        "for confidence_metric in uncertainties_bayes_5['correct'].keys():\n",
        "    confidence = uncertainties_bayes_5['all'][confidence_metric]\n",
        "    if confidence_metric == \"entropy\":\n",
        "        confidence = 1- confidence\n",
        "    sens = list()\n",
        "    fpr = list()\n",
        "    for threshold in np.arange(0, 1, 0.1):\n",
        "        df_not_confident = df_features_collision_nonan_5[confidence <= threshold]\n",
        "        anomaly_indexes = list()\n",
        "        tp = 0\n",
        "        for anomaly in collisions_init:\n",
        "            for index, row in df_not_confident.iterrows():\n",
        "                if anomaly >= row['start'] and anomaly <= row['end']:\n",
        "                    anomaly_indexes.append(index)\n",
        "                    tp += 1\n",
        "\n",
        "        cm_anomaly = np.zeros((2, 2))\n",
        "        n_samples = len(df_features_collision_nonan_5)\n",
        "        n_not_collisions = n_samples - len(collisions_init)\n",
        "        n_detected = len(df_not_confident)\n",
        "\n",
        "        fp = n_detected - tp\n",
        "        fn = len(collisions_init) - tp\n",
        "        tn = n_not_collisions - fp\n",
        "        cm_anomaly[0][0] = tn\n",
        "        cm_anomaly[1][1] = tp\n",
        "        cm_anomaly[0][1] = fp\n",
        "        cm_anomaly[1][0] = fn\n",
        "        sens.append(tp / (tp + fn))\n",
        "        fpr.append(1 - tn / (fp + tn))\n",
        "    roc_dict[confidence_metric] = (fpr, sens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1, 1)\n",
        "for confidence_metric in uncertainties_bayes_5['correct'].keys():\n",
        "    ax.plot(roc_dict[confidence_metric][0], roc_dict[confidence_metric][1], label=confidence_metric)\n",
        "ax.legend();"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
