{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group 14 - Project FP01\n",
    "## Time series anomaly detection - XGBoost\n",
    "\n",
    "This project aims at investigating the current state-of-the-arts TAD scenario using XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas==1.5.3\n",
    "# !pip install tsfel\n",
    "# !pip install xgboost\n",
    "# !pip install -U kaleido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import tsfel\n",
    "import warnings\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from dataset import get_df_action, get_features_ts, get_train_test_data\n",
    "from plots import seaborn_cm, create_and_plot_cm, plot_uncertainty, plot_signals, plot_anomalies, plot_anomalies_over_time, plot_roc_curve\n",
    "from metrics import Confidence, anomaly_detection_metric, compute_metrics\n",
    "\n",
    "# Set style for matplotlib\n",
    "plt.style.use(\"Solarize_Light2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the root directory of the dataset\n",
    "ROOTDIR_DATASET_NORMAL = '../../dataset/normal'\n",
    "ROOTDIR_DATASET_ANOMALY = '../../dataset/collisions'\n",
    "\n",
    "import os\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset: Kuka-v1\n",
    "In 5 different recording sessions, the robot executes several different operations, while being monitored by several sensors. The sensed signals are collected, with different sampling frequencies (1, 10, 100, 200 Hz)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = '0.1'\n",
    "\n",
    "# NORMAL DATA\n",
    "filepath_csv = [os.path.join(ROOTDIR_DATASET_NORMAL, f\"rec{r}_20220811_rbtc_{freq}s.csv\") for r in [0, 2, 3, 4]]\n",
    "filepath_meta = [os.path.join(ROOTDIR_DATASET_NORMAL, f\"rec{r}_20220811_rbtc_{freq}s.metadata\") for r in [0, 2, 3, 4]]\n",
    "df_action, df, df_meta, action2int = get_df_action(filepath_csv, filepath_meta)\n",
    "\n",
    "# COLLISION DATA\n",
    "xls = pd.ExcelFile(os.path.join(ROOTDIR_DATASET_ANOMALY, \"20220811_collisions_timestamp.xlsx\"))\n",
    "collision_rec1 = pd.read_excel(xls, 'rec1')\n",
    "collision_rec5 = pd.read_excel(xls, 'rec5')\n",
    "\n",
    "collisions = pd.concat([collision_rec1, collision_rec5])\n",
    "collisions_init = collisions[collisions['Inizio/fine'] == \"i\"].Timestamp - pd.to_timedelta([2] * len(collisions[collisions['Inizio/fine'] == \"i\"].Timestamp), 'h')\n",
    "\n",
    "filepath_csv = [os.path.join(ROOTDIR_DATASET_ANOMALY, f\"rec{r}_collision_20220811_rbtc_{freq}s.csv\") for r in [1, 5]]\n",
    "filepath_meta = [os.path.join(ROOTDIR_DATASET_ANOMALY, f\"rec{r}_collision_20220811_rbtc_{freq}s.metadata\") for r in [1, 5]]\n",
    "df_action_collision, df_collision, df_meta_collision, action2int_collision = get_df_action(filepath_csv, filepath_meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "frequency = 1/float(freq)\n",
    "df_features = get_features_ts(\"statistical\", df_action, df_meta, frequency, action2int)\n",
    "df_features_collision = get_features_ts(\"statistical\", df_action_collision, df_meta_collision, frequency, action2int_collision)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = get_train_test_data(df_features, df_features_collision, full_normal=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost for Anomaly Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train XGBoost model\n",
    "xgb_model = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"XGBoost training completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anomaly Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use predict_proba to get probability scores\n",
    "anomaly_scores = 1 - xgb_model.predict_proba(X_test)[:, 0]  # Use the probability of not being in the majority class\n",
    "plot_anomalies(xgb_model, X_test, y_test, freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_scores, y_test_binary = compute_metrics(xgb_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve(y_test_binary, anomaly_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map anomalies to original time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_anomalies_over_time(X_test, anomaly_scores, sum(anomaly_scores > np.mean(anomaly_scores) + 2 * np.std(anomaly_scores)), freq)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
