{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group 14 - Project FP01\n",
    "## Time series anomaly detection\n",
    "\n",
    "This project aims at investigating the current state-of-the-arts TAD scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\VG User\\Documents\\GitHub\\MLinAPP-FP01-14\\.venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import tsfel\n",
    "import warnings\n",
    "import datetime\n",
    "import keras_tuner\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib.cm as cm\n",
    "from sklearn import metrics\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "\n",
    "import dataset as ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the root directory of the dataset\n",
    "ROOTDIR_DATASET_NORMAL = './dataset/normal/'\n",
    "ROOTDIR_DATASET_COLLISION = './dataset/collisions/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF_ENABLE_ONEDNN_OPTS=0 means that the model will not use the oneDNN library for optimization\n",
    "\n",
    "import os\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset: Kuka-v1\n",
    "In 5 different recording sessions, the robot executes several different operations, while being\n",
    "monitored by several sensors. The sensed signals are collected, with different sampling frequencies\n",
    "(1, 10, 100, 200 Hz),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset frequency\n",
    "freq_01s = '0.1'\n",
    "freq_001s = '0.01'\n",
    "freq_0005s = '0.005'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data.\n",
      "Found 31 different actions.\n",
      "Loading data done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_action, df, df_meta, action2int = ds.load_data(ROOTDIR_DATASET_NORMAL, freq_01s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction\n",
    "In this section the feature from the dataset is extracted, then the train and test data is split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing features.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "              <p>\n",
       "                  Progress: 0% Complete\n",
       "              <p/>\n",
       "              <progress\n",
       "                  value='0'\n",
       "                  max='32',\n",
       "                  style='width: 25%',\n",
       "              >\n",
       "                  0\n",
       "              </progress>\n",
       "\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped feature extraction for pickFromPallet(1,2)=[true,1,0] 2022-08-11 14:37:37.436000 : 2022-08-11 14:37:37.421000.\n",
      "Skipped feature extraction for placeToPallet(1,1)=[true,0] 2022-08-11 14:37:37.421000 : 2022-08-11 14:37:37.442000.\n",
      "Skipped feature extraction for pickFromPallet(3,2)=[true,1,0] 2022-08-11 15:36:32.568000 : 2022-08-11 15:36:32.533000.\n",
      "Skipped feature extraction for pickFromPallet(3,2)=[true,1,0] 2022-08-11 15:36:32.572000 : 2022-08-11 15:36:32.561000.\n",
      "Skipped feature extraction for placeToPallet(1,3)=[true,0] 2022-08-11 15:36:32.533000 : 2022-08-11 15:36:32.572000.\n",
      "Skipped feature extraction for placeToPallet(1,3)=[true,0] 2022-08-11 15:36:32.561000 : 2022-08-11 15:36:32.561000.\n",
      "Computing features done.\n",
      "--- 86.56909990310669 seconds ---\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = ds.get_train_test_data_df(df_action=df_action, df_meta=df_meta, action2int=action2int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise features\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = pd.DataFrame(scaler.transform(X_train), columns=X_train.columns)\n",
    "\n",
    "# Remove zero-variance features\n",
    "selector_variance = VarianceThreshold()\n",
    "selector_variance.fit(X_train)\n",
    "X_train = pd.DataFrame(selector_variance.transform(X_train),\n",
    "                        columns=X_train.columns.values[selector_variance.get_support()])\n",
    "\n",
    "# Remove highly correlated features\n",
    "corr_features = tsfel.correlated_features(X_train,\n",
    "                                          threshold=0.95)\n",
    "X_train.drop(corr_features, inplace=True, axis=1)\n",
    "\n",
    "# Lasso selector\n",
    "lsvc = LinearSVC(C=0.01, penalty=\"l1\", dual=False).fit(X_train, y_train)\n",
    "lasso = SelectFromModel(lsvc, prefit=True)\n",
    "selected_features = X_train.columns.values[lasso.get_support()]\n",
    "X_train = X_train[selected_features].copy()\n",
    "\n",
    "# Labels\n",
    "num_classes = len(set(y_train))\n",
    "y_train_categorical = tf.keras.utils.to_categorical(y_train, num_classes=num_classes)\n",
    "\n",
    "# Test\n",
    "X_test = pd.DataFrame(selector_variance.transform(scaler.transform(X_test)),\n",
    "                      columns=X_test.columns.values[selector_variance.get_support()])\n",
    "X_test.drop(corr_features, inplace=True, axis=1)\n",
    "X_test = X_test[selected_features].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph import seaborn_cm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def create_and_plot_cm (y_pred, y_true):\n",
    "    cm = confusion_matrix(y_true, y_pred.argmax(axis=1), labels=list(action2int.values()))\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "    int2action = {v: k for k, v in action2int.items()}\n",
    "    seaborn_cm(cm,\n",
    "                ax,\n",
    "                [int2action[l] for l in action2int.values()], fontsize=8, xrotation=90)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (X_train.values.shape[1],)\n",
    "num_classes = len(y_train_categorical[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian MLP for Anomaly Detection from Lab 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayesian_model import BayesianMLPClassifier\n",
    "\n",
    "clf = BayesianMLPClassifier(input_shape, num_classes)\n",
    "clf.setup_tuner()\n",
    "\n",
    "clf.search(X_train.values, y_train_categorical)\n",
    "y_test_pred = clf.predict(X_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_and_plot_cm(y_test_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Confidence:\n",
    "\n",
    "    def __init__(self, multiple_preds):\n",
    "        self.multiple_preds = multiple_preds\n",
    "        self._uncertainty_metrics = dict()\n",
    "        self._uncertainty_metrics['entropy'] = self._entropy\n",
    "        self._uncertainty_metrics['variance'] = self._variance\n",
    "        self._uncertainty_metrics['max_softmax_response'] = self._max_softmax_response\n",
    "\n",
    "    def compute_uncertainty_metrics(self):\n",
    "        return {metric: self._compute_uncertainty(\n",
    "            metric,\n",
    "            self.multiple_preds) for metric in self._uncertainty_metrics.keys()}\n",
    "\n",
    "    def _normalize(self, values):\n",
    "            return (values - values.min())/(values.max()-values.min())\n",
    "\n",
    "    def _compute_uncertainty(self, metric, multiple_preds):\n",
    "        try:\n",
    "            print(\"Done {}\".format(metric))\n",
    "            return self._normalize(\n",
    "                self._uncertainty_metrics[metric](multiple_preds))\n",
    "        except KeyError:\n",
    "            print(\"{} not implemented.\".format(metric))\n",
    "\n",
    "    def _avreage_prediction(self, multiple_preds):\n",
    "        if len(multiple_preds.shape) > 2:\n",
    "            return np.mean(np.array(multiple_preds), axis=0)\n",
    "        else:\n",
    "            return multiple_preds\n",
    "\n",
    "    def _entropy(self, multiple_preds):\n",
    "        avg_preds = self._avreage_prediction(multiple_preds)\n",
    "        eps = 1e-5\n",
    "        entropy = -1 * np.sum(avg_preds * np.log(avg_preds + eps), axis=1)\n",
    "        return entropy\n",
    "\n",
    "    def _variance(self, multiple_preds):\n",
    "        avg_preds = self._avreage_prediction(multiple_preds)\n",
    "        return  np.var(avg_preds, axis=1)\n",
    "\n",
    "    def _max_softmax_response(self, multiple_preds):\n",
    "        avg_preds = self._avreage_prediction(multiple_preds)\n",
    "        return np.max(avg_preds, axis=1)\n",
    "\n",
    "def anomaly_detection_metric(anomaly_start_timestamps, confidence, df_dataset, thresholds, less_than=True):\n",
    "    \"Actual is y axis\"\n",
    "    if not less_than:\n",
    "        confidence = 1 - confidence\n",
    "\n",
    "    sens = list()\n",
    "    spec = list()\n",
    "    fpr = list()\n",
    "    f1 = list()\n",
    "    prec = list()\n",
    "    cm_list = list()\n",
    "    anomaly_indexes_dict = dict()\n",
    "    acc_with_err = list()\n",
    "    for threshold in thresholds:\n",
    "        df_not_confident = df_dataset[confidence <= threshold]\n",
    "        tp = 0\n",
    "        anomaly_indexes = list()\n",
    "        for anomaly in anomaly_start_timestamps:\n",
    "            for index, row in df_not_confident.iterrows():\n",
    "                if anomaly >= row['start'] and anomaly <= row['end']:\n",
    "                    anomaly_indexes.append(index)\n",
    "                    tp += 1\n",
    "\n",
    "        cm_anomaly = np.zeros((2, 2))\n",
    "        n_samples = len(df_dataset)\n",
    "        n_not_collisions = n_samples - len(anomaly_start_timestamps)\n",
    "        n_detected = len(df_not_confident)\n",
    "\n",
    "        fp = n_detected - tp\n",
    "        fn = len(anomaly_start_timestamps) - tp\n",
    "        tn = n_not_collisions - fp\n",
    "\n",
    "        cm_anomaly[0][0] = tn\n",
    "        cm_anomaly[1][1] = tp\n",
    "        cm_anomaly[0][1] = fp\n",
    "        cm_anomaly[1][0] = fn\n",
    "        cm_list.append(cm_anomaly)\n",
    "        sens.append(tp / (tp + fn))\n",
    "        recall = tp / (tp + fn)\n",
    "        prec.append(tp / (tp + fp))\n",
    "        spec.append(tn / (fp + tn))\n",
    "        fpr.append(1 - tn / (fp + tn))\n",
    "        try:\n",
    "            f1.append(2 * tp / (2 * tp + fp + fn) )\n",
    "        except ZeroDivisionError:\n",
    "            f1.append(0)\n",
    "        cm_anomaly_norm = cm_anomaly.astype('float') / cm_anomaly.sum(axis=1)[:, np.newaxis]\n",
    "        acc_with_err.append((np.mean(np.diag(cm_anomaly_norm)),\n",
    "                            np.std(np.diag(cm_anomaly_norm))))\n",
    "\n",
    "\n",
    "        anomaly_indexes_dict[threshold] = anomaly_indexes\n",
    "    return sens, spec, fpr, f1, cm_list, anomaly_indexes_dict, acc_with_err, prec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_mc = 10\n",
    "preds_array = np.array([y_test_pred])\n",
    "preds_bayes_mean = np.mean(preds_array, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncertainties_bayes = dict()\n",
    "uncertainties_bayes[\"correct\"] = Confidence(preds_array.mean(axis=0)[(preds_bayes_mean.argmax(axis=1) == y_test), :]).compute_uncertainty_metrics()\n",
    "uncertainties_bayes[\"wrong\"] = Confidence(preds_array.mean(axis=0)[(preds_bayes_mean.argmax(axis=1) != y_test), :]).compute_uncertainty_metrics()\n",
    "uncertainties_bayes[\"all\"] = Confidence(preds_array.mean(axis=0)).compute_uncertainty_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set style for matplotlib\n",
    "plt.style.use(\"Solarize_Light2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_uncertainty(uncertainties, title):\n",
    "    fig, axes = plt.subplots(len(uncertainties['correct'].keys()), 3, figsize=(15, 9))\n",
    "    for ax, measure in zip(axes, uncertainties['correct'].keys()):\n",
    "        ax[0].set_title(f\"Wrong - {measure}\")\n",
    "        ax[0].hist(uncertainties['wrong'][measure], color=\"red\", log=False, bins=25, edgecolor='black', linewidth=1.2, alpha=0.5);\n",
    "        ax[1].set_title(f\"Correct - {measure}\")\n",
    "        ax[1].hist(uncertainties['correct'][measure], color=\"green\", log=False, bins=25, edgecolor='black', linewidth=1.2, alpha=0.5);\n",
    "        ax[2].set_title(f\"All - {measure}\")\n",
    "        ax[2].hist(uncertainties['all'][measure], color=\"blue\", log=False, bins=25, edgecolor='black', linewidth=1.2, alpha=0.5);\n",
    "    fig.suptitle(title, fontsize=20)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_uncertainty(uncertainties_bayes, \"Bayesian MLP Uncertainty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnn_model import CNNClassifier\n",
    "\n",
    "clf = CNNClassifier(input_shape, num_classes)\n",
    "clf.setup_tuner()\n",
    "\n",
    "clf.search(X_train.values, y_train_categorical)\n",
    "y_test_pred = clf.predict(X_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_and_plot_cm(y_test_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_mc = 10\n",
    "preds_array = np.array([y_test_pred])\n",
    "preds_bayes_mean = np.mean(preds_array, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncertainties_bayes = dict()\n",
    "uncertainties_bayes[\"correct\"] = Confidence(preds_array.mean(axis=0)[(preds_bayes_mean.argmax(axis=1) == y_test), :]).compute_uncertainty_metrics()\n",
    "uncertainties_bayes[\"wrong\"] = Confidence(preds_array.mean(axis=0)[(preds_bayes_mean.argmax(axis=1) != y_test), :]).compute_uncertainty_metrics()\n",
    "uncertainties_bayes[\"all\"] = Confidence(preds_array.mean(axis=0)).compute_uncertainty_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_uncertainty(uncertainties_bayes, \"Bayesian CNN Uncertainty\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
