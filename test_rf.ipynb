{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7skbGH4Urm1T"
      },
      "source": [
        "# Group 14 - Project FP01\n",
        "## Time series anomaly detection - Random Forest Classifier\n",
        "\n",
        "This project aims at investigating the current state-of-the-arts TAD scenario."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mWByyf-sEML",
        "outputId": "26f53cfe-2b91-48c2-ab3c-30e9531e475f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas==1.5.3 in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas==1.5.3) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas==1.5.3) (2023.4)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas==1.5.3) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas==1.5.3) (1.16.0)\n",
            "Requirement already satisfied: tsfel in /usr/local/lib/python3.10/dist-packages (0.1.7)\n",
            "Requirement already satisfied: ipython>=7.4.0 in /usr/local/lib/python3.10/dist-packages (from tsfel) (7.34.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from tsfel) (1.25.2)\n",
            "Requirement already satisfied: pandas>=1.5.3 in /usr/local/lib/python3.10/dist-packages (from tsfel) (1.5.3)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from tsfel) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.7.3 in /usr/local/lib/python3.10/dist-packages (from tsfel) (1.11.4)\n",
            "Requirement already satisfied: setuptools>=47.1.1 in /usr/local/lib/python3.10/dist-packages (from tsfel) (67.7.2)\n",
            "Requirement already satisfied: statsmodels>=0.12.0 in /usr/local/lib/python3.10/dist-packages (from tsfel) (0.14.2)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.4.0->tsfel) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=7.4.0->tsfel) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=7.4.0->tsfel) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.4.0->tsfel) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.4.0->tsfel) (3.0.47)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=7.4.0->tsfel) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=7.4.0->tsfel) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=7.4.0->tsfel) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.4.0->tsfel) (4.9.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.5.3->tsfel) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.5.3->tsfel) (2023.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->tsfel) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->tsfel) (3.5.0)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.12.0->tsfel) (0.5.6)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.12.0->tsfel) (24.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=7.4.0->tsfel) (0.8.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.6->statsmodels>=0.12.0->tsfel) (1.16.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=7.4.0->tsfel) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.4.0->tsfel) (0.2.13)\n",
            "Requirement already satisfied: keras_tuner in /usr/local/lib/python3.10/dist-packages (1.4.7)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras_tuner) (2.15.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras_tuner) (24.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras_tuner) (2.31.0)\n",
            "Requirement already satisfied: kt-legacy in /usr/local/lib/python3.10/dist-packages (from keras_tuner) (1.0.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (2024.7.4)\n",
            "Requirement already satisfied: kaleido in /usr/local/lib/python3.10/dist-packages (0.2.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas==1.5.3\n",
        "!pip install tsfel\n",
        "!pip install keras_tuner\n",
        "!pip install -U kaleido"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "O8r-brr8rm1Z"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import tsfel\n",
        "import warnings\n",
        "import datetime\n",
        "import keras_tuner as kt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "import matplotlib.cm as cm\n",
        "from sklearn import metrics\n",
        "import plotly.express as px\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import preprocessing\n",
        "import plotly.graph_objects as go\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import auc\n",
        "\n",
        "from dataset import get_df_action, get_features_ts, get_train_test_data, label_collision_data\n",
        "from plots import seaborn_cm, create_and_plot_cm, plot_uncertainty, plot_signals, plot_anomalies, plot_anomalies_over_time, plot_roc_curve\n",
        "from metrics import Confidence, anomaly_detection_metric, compute_metrics\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Set style for matplotlib\n",
        "plt.style.use(\"Solarize_Light2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpdYISeFq1QD",
        "outputId": "e44b43fe-3cad-4781-8e2f-749fb21e9238"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4mylEXUIrm1g"
      },
      "outputs": [],
      "source": [
        "# Path to the root directory of the dataset\n",
        "ROOTDIR_DATASET_NORMAL =  '/content/drive/MyDrive/dataset/normal'#'../dataset/normal'0\n",
        "ROOTDIR_DATASET_ANOMALY = '/content/drive/MyDrive/dataset/collisions'#'../dataset/collisions'\n",
        "\n",
        "# TF_ENABLE_ONEDNN_OPTS=0 means that the model will not use the oneDNN library for optimization\n",
        "\n",
        "import os\n",
        "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fuWTQHSrm1i"
      },
      "source": [
        "### Dataset: Kuka-v1\n",
        "In 5 different recording sessions, the robot executes several different operations, while being\n",
        "monitored by several sensors. The sensed signals are collected, with different sampling frequencies\n",
        "(1, 10, 100, 200 Hz),"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-vhG81Qrm1k"
      },
      "source": [
        "### Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyHvPhF9rm1m",
        "outputId": "d5b4e643-b119-459d-8d70-a1c9ae4ff619"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data.\n",
            "Found 31 different actions.\n",
            "Loading data done.\n",
            "\n",
            "Loading data.\n",
            "Found 31 different actions.\n",
            "Loading data done.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#freq = '1.0'\n",
        "freq = '0.1'\n",
        "#freq = '0.01'\n",
        "#freq = '0.005'\n",
        "\n",
        "# NORMAL DATA\n",
        "filepath_csv = [os.path.join(ROOTDIR_DATASET_NORMAL, f\"rec{r}_20220811_rbtc_{freq}s.csv\") for r in [0, 2, 3, 4]]\n",
        "filepath_meta = [os.path.join(ROOTDIR_DATASET_NORMAL, f\"rec{r}_20220811_rbtc_{freq}s.metadata\") for r in [0, 2, 3, 4]]\n",
        "df_action, df, df_meta, action2int = get_df_action(filepath_csv, filepath_meta)\n",
        "\n",
        "\n",
        "# COLLISION DATA\n",
        "xls = pd.ExcelFile(os.path.join(ROOTDIR_DATASET_ANOMALY, \"20220811_collisions_timestamp.xlsx\"))\n",
        "collision_rec1 = pd.read_excel(xls, 'rec1')\n",
        "collision_rec5 = pd.read_excel(xls, 'rec5')\n",
        "\n",
        "collisions = pd.concat([collision_rec1, collision_rec5])\n",
        "collisions_init = collisions[collisions['Inizio/fine'] == \"i\"].Timestamp - pd.to_timedelta([2] * len(collisions[collisions['Inizio/fine'] == \"i\"].Timestamp), 'h')\n",
        "\n",
        "collisions_adjusted = collisions.Timestamp - pd.to_timedelta([2] * len(collisions.Timestamp), 'h')\n",
        "# transform in like collision\n",
        "collisions['Timestamp'] = collisions_adjusted\n",
        "\n",
        "filepath_csv = [os.path.join(ROOTDIR_DATASET_ANOMALY, f\"rec{r}_collision_20220811_rbtc_{freq}s.csv\") for r in [1, 5]]\n",
        "filepath_meta = [os.path.join(ROOTDIR_DATASET_ANOMALY, f\"rec{r}_collision_20220811_rbtc_{freq}s.metadata\") for r in [1, 5]]\n",
        "df_action_collision, df_collision, df_meta_collision, action2int_collision = get_df_action(filepath_csv, filepath_meta)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAS5s6nIms1S"
      },
      "source": [
        "### Features Exctraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "YCf6T1CBrm1q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "outputId": "b2d0fdac-3933-4e74-bb1d-9acbb072d438"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing features.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "              <p>\n",
              "                  Progress: 0% Complete\n",
              "              <p/>\n",
              "              <progress\n",
              "                  value='0'\n",
              "                  max='32',\n",
              "                  style='width: 25%',\n",
              "              >\n",
              "                  0\n",
              "              </progress>\n",
              "\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipped feature extraction for pickFromPallet(1,2)=[true,1,0] 2022-08-11 14:37:37.436000 : 2022-08-11 14:37:37.421000.\n",
            "Skipped feature extraction for placeToPallet(1,1)=[true,0] 2022-08-11 14:37:37.421000 : 2022-08-11 14:37:37.442000.\n",
            "Skipped feature extraction for pickFromPallet(3,2)=[true,1,0] 2022-08-11 15:36:32.568000 : 2022-08-11 15:36:32.533000.\n",
            "Skipped feature extraction for pickFromPallet(3,2)=[true,1,0] 2022-08-11 15:36:32.572000 : 2022-08-11 15:36:32.561000.\n",
            "Skipped feature extraction for placeToPallet(1,3)=[true,0] 2022-08-11 15:36:32.533000 : 2022-08-11 15:36:32.572000.\n",
            "Skipped feature extraction for placeToPallet(1,3)=[true,0] 2022-08-11 15:36:32.561000 : 2022-08-11 15:36:32.561000.\n",
            "Computing features done.\n",
            "Computing features.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "              <p>\n",
              "                  Progress: 0% Complete\n",
              "              <p/>\n",
              "              <progress\n",
              "                  value='0'\n",
              "                  max='12',\n",
              "                  style='width: 25%',\n",
              "              >\n",
              "                  0\n",
              "              </progress>\n",
              "\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipped feature extraction for moveOverPallet(1,3)=[true,0] 2022-08-11 16:55:15.149000 : 2022-08-11 16:55:15.146000.\n",
            "Skipped feature extraction for moveOverPallet(3,1)=[true,0] 2022-08-11 16:55:15.146000 : 2022-08-11 16:55:15.150000.\n",
            "Computing features done.\n",
            "--- 290.2463438510895 seconds ---\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "frequency = 1/float(freq)\n",
        "df_features = get_features_ts(\"statistical\", df_action, df_meta, frequency, action2int)\n",
        "df_features_collision = get_features_ts(\"statistical\", df_action_collision, df_meta_collision, frequency, action2int_collision)\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w4fgcVqIrm1r"
      },
      "outputs": [],
      "source": [
        "X_train, y_train, X_test, y_test = get_train_test_data(df_features, df_features_collision)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_with_labels = label_collision_data(df_features_collision, collisions_init)\n",
        "y_test_collision = df_with_labels[\"is_collision\"]"
      ],
      "metadata": {
        "id": "8i13eyL26cbd"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trying to take collision_zones\n",
        "\n"
      ],
      "metadata": {
        "id": "RcGkEcXLLWmI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "idx_starts = collisions[collisions['Inizio/fine'] == 'i'].index\n",
        "idx_ends = collisions[collisions['Inizio/fine'] == 'f'].index\n",
        "ts_starts = collisions[collisions['Inizio/fine'] == 'i'].Timestamp.reset_index()\n",
        "ts_ends = collisions[collisions['Inizio/fine'] == 'f'].Timestamp.reset_index()\n",
        "\n",
        "d = {'start': ts_starts.Timestamp, 'end': ts_ends.Timestamp}\n",
        "\n",
        "collision_zones = pd.DataFrame(d)\n",
        "\n",
        "print(X_test['timestamp'])"
      ],
      "metadata": {
        "id": "weZx8M0iLOeQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dt7jTbyH1tKk"
      },
      "source": [
        "\n",
        "## Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jgqFpq95krY5"
      },
      "outputs": [],
      "source": [
        "num_estims = [10, 100, 1000]\n",
        "crits = ['gini', 'entropy', 'log_loss']\n",
        "max_dept = [None, 50, 100, 1000]\n",
        "min_s_splits = [2, 3]\n",
        "max_features = ['sqrt', 'log2', None]\n",
        "fitted_clfs = []\n",
        "\n",
        "classifier = RandomForestClassifier(\n",
        "    n_estimators = 100,\n",
        "    criterion = 'entropy',\n",
        "    max_depth = 100,\n",
        "    min_samples_split = 2,\n",
        "    max_features = 'sqrt'\n",
        "    )\n",
        "# Train the RandomForestClassifier on normal data\n",
        "classifier.fit(X_train, y_train)\n",
        "fitted_clfs.append(classifier)\n",
        "print(\"Random Forest training completed.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rmr_gKxWkrY5"
      },
      "source": [
        "### Anomaly Detection"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "anomaly_scores = None\n",
        "try:\n",
        "    anomaly_scores = classifier.predict(X_test)\n",
        "    # Replace inf values with the maximum float value\n",
        "    anomaly_scores = np.nan_to_num(anomaly_scores, nan=np.nanmean(anomaly_scores), posinf=np.finfo(float).max, neginf=np.finfo(float).min)\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred during prediction: {str(e)}\")\n",
        "    # If an error occurs, you might want to inspect the model's internal state\n",
        "print(\"Anomaly prediction completed.\")"
      ],
      "metadata": {
        "id": "fJIPz_CO5RCW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "threshold_1 = np.mean(anomaly_scores) + 2 * np.std(anomaly_scores)"
      ],
      "metadata": {
        "id": "UrypdSJR5W--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "median = np.median(anomaly_scores)\n",
        "mad = np.median(np.abs(anomaly_scores - median))\n",
        "threshold_2 = median + 3 * mad"
      ],
      "metadata": {
        "id": "VT1PKZZi5ZGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "threshold_3 = np.percentile(anomaly_scores, 95)"
      ],
      "metadata": {
        "id": "uc8nH9Y15blV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q1 = np.percentile(anomaly_scores, 25)\n",
        "Q3 = np.percentile(anomaly_scores, 75)\n",
        "IQR = Q3 - Q1\n",
        "threshold_4 = Q3 + 1.5 * IQR"
      ],
      "metadata": {
        "id": "I4mXq8TK5dPV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for threshold in [threshold_1, threshold_2, threshold_3, threshold_4]:\n",
        "    anomalies_detected = sum(anomaly_scores >= threshold)\n",
        "    print(f\"Number of anomalies detected: {anomalies_detected} with threshold {threshold}\")"
      ],
      "metadata": {
        "id": "K6thJ4fF5fZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "anomalies_detected = plot_anomalies(anomaly_scores, freq, threshold_2)"
      ],
      "metadata": {
        "id": "t7gOiFkS6ml-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o5L9QwuonXxv"
      },
      "outputs": [],
      "source": [
        "# for classifier in fitted_clfs:\n",
        "#   print(\"-------------------------------------------- New classifier --------------------------------------------\")\n",
        "compute_metrics(anomaly_scores, y_test_collision, threshold_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l9RHji6ynXxw"
      },
      "outputs": [],
      "source": [
        "plot_roc_curve(y_test_collision.values, anomaly_scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxYU84_vp6Un"
      },
      "source": [
        "## Map anomalies to original time series"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "threshold_2"
      ],
      "metadata": {
        "id": "koWWmiWFCHR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "nZiKdqzFp5Ev"
      },
      "outputs": [],
      "source": [
        "plot_anomalies_over_time(X_test, anomaly_scores, anomalies_detected, freq, threshold_2, collision_zones)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}